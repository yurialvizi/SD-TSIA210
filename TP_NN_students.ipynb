{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iafPdtuncbq7"
   },
   "source": [
    "# TP: MNIST with Neural Networks (NN)\n",
    "\n",
    "## Students\n",
    "- Raynner Schnneider Carvalho\n",
    "- Yuri de Sene Alvizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OlKZ3Hnas7B4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow version 2.16.1\n",
      "Using keras version 3.3.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print(\"Using tensorflow version \" + str(tf.__version__))\n",
    "print(\"Using keras version \" + str(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_QLz9_jbRZq"
   },
   "source": [
    "## Loading and preparing the MNIST dataset\n",
    "Load the MNIST dataset made available by keras.datasets. Check the size of the training and testing sets. \n",
    "\n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "gG83hGyVmijn"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Images</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>(60000, 28, 28)</td>\n",
       "      <td>(60000,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>(10000, 28, 28)</td>\n",
       "      <td>(10000,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Images    Labels\n",
       "Train  (60000, 28, 28)  (60000,)\n",
       "Test   (10000, 28, 28)  (10000,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The MNSIT dataset is ready to be imported from Keras into RAM\n",
    "# Warning: you cannot do that for larger databases (e.g., ImageNet)\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Let's check the size of the data\n",
    "df = pd.DataFrame([[train_images.shape, train_labels.shape], [test_images.shape, test_labels.shape]], columns=['Images', 'Labels'], index=['Train', 'Test'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRPbU_Z4U6Ac"
   },
   "source": [
    "The MNIST database contains 60,000 training images and 10,000 testing images.\n",
    "Using the pyplot package, visualize the first sample of the training set:\n",
    "\n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5VAu7oW0Zu4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let us visualize the first training sample using the Matplotlib library with the imshow function\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "plt.title('Class label: ' + str(train_labels[0]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7YsRekMVDg-"
   },
   "source": [
    "The database contains images of handwritten digits. Hence, they belong to one of 10 categories, depending on the digit they represent. \n",
    "Reminder: in order to do multi-class classification, we use the softmax function, which outputs a multinomial probability distribution. That means that the output to our model will be a vector of size $10$, containing probabilities (meaning that the elements of the vector will be positive sum to $1$).\n",
    "For easy computation, we want to true labels to be represented with the same format: that is what we call **one-hot encoding**. For example, if an image $\\mathbf{x}$ represents the digit $5$, we have the corresponding one_hot label (careful, $0$ will be the first digit): \n",
    "$$ \\mathbf{y} = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0] $$\n",
    "Here, you need to turn train and test labels to one-hot encoding using the following function: \n",
    "\n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQbkllF8mnaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot encoding train labels shape: (60000, 10)\n",
      "One hot encoding test labels shape: (10000, 10)\n",
      "Original label example: 1\n",
      "One hot encoding example: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)\n",
    "\n",
    "print(\"One hot encoding train labels shape: \" + str(one_hot_train_labels.shape))\n",
    "print(\"One hot encoding test labels shape: \" + str(one_hot_test_labels.shape))\n",
    "\n",
    "# Example of one hot encoding label\n",
    "example_label_idx = 3\n",
    "print(\"Original label example: \" + str(train_labels[example_label_idx]))\n",
    "print(\"One hot encoding example: \" + str(one_hot_train_labels[example_label_idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jv29YLtVO3q"
   },
   "source": [
    "Images are black and white, with size $28 \\times 28$. We will work with them using a simple linear classification model, meaning that we will have them as vectors of size $(784)$.\n",
    "You should then transform the images to the size $(784)$ using the numpy function ```reshape```.\n",
    "\n",
    "Then, after casting the pixels to floats, normalize the images so that they have zero-mean and unitary deviation. Be careful to your methodology: while you have access to training data, you may not have access to testing data, and must avoid using any statistic on the testing dataset.\n",
    "\n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ptTRSDo5nJyZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28)\n",
      "Mean of the first image: 0.0\n",
      "Std of the first image: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Reshape images to vectors of pixels\n",
    "img_rows, img_cols = train_images.shape[1], train_images.shape[2]\n",
    "train_images_reshaped = train_images.reshape(train_images.shape[0], img_rows * img_cols)\n",
    "print(\"Training data shape: \" + str(train_images.shape))\n",
    "\n",
    "# Cast pixels from uint8 to float32\n",
    "train_images_reshaped = train_images_reshaped.astype('float32')\n",
    "\n",
    "# Now let us normalize the images so that they have zero mean and standard deviation\n",
    "# Hint: are real testing data statistics known at training time ?\n",
    "\n",
    "mean_image = np.mean(train_images_reshaped, axis=1, keepdims=True)\n",
    "std_image = np.std(train_images_reshaped, axis=1, keepdims=True)\n",
    "\n",
    "train_images_reshaped_norm = (train_images_reshaped - mean_image) / std_image\n",
    "\n",
    "# Let us check the mean and std of the first image\n",
    "print(\"Mean of the first image: \" + str(np.mean(train_images_reshaped_norm[0])))\n",
    "print(\"Std of the first image: \" + str(np.std(train_images_reshaped_norm[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First part: working with Numpy\n",
    "\n",
    "Look at this [cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf) for some basic information on how to use numpy.\n",
    "\n",
    "### Defining the model \n",
    "\n",
    "We will here create a simple, linear classification model. We will take each pixel in the image as an input feature (making the size of the input to be $784$) and transform these features with a weight matrix $\\mathbf{W}$ and a bias vector $\\mathbf{b}$. Since there is $10$ possible classes, we want to obtain $10$ scores. Then, \n",
    "$$ \\mathbf{W} \\in \\mathbb{R}^{784 \\times 10} $$\n",
    "$$ \\mathbf{b} \\in \\mathbb{R}^{10} $$\n",
    "\n",
    "and our scores are obtained with:\n",
    "$$ \\mathbf{z} = \\mathbf{W}^{T} \\mathbf{x} +  \\mathbf{b} $$\n",
    "\n",
    "where $\\mathbf{x} \\in \\mathbb{R}^{784}$ is the input vector representing an image.\n",
    "We note $\\mathbf{y} \\in \\mathbb{R}^{10}$ as the target one_hot vector. \n",
    "\n",
    "Here, you fist need to initialize $\\mathbf{W}$ and $\\mathbf{b}$ using ```np.random.normal``` and ```np.zeros```, then compute $\\mathbf{z}$.\n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid implementing a complicated gradient back-propagation,\n",
    "# we will try a very simple architecture with one layer \n",
    "def initLayer(n_input,n_output):\n",
    "    \"\"\"\n",
    "    Initialize the weights, return the number of parameters\n",
    "    Inputs: n_input: the number of input units - int\n",
    "          : n_output: the number of output units - int\n",
    "    Outputs: W: a matrix of weights for the layer - numpy ndarray\n",
    "           : b: a vector bias for the layer - numpy ndarray\n",
    "           : nb_params: the number of parameters  - int\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Create W at the right size with a normal distribution\n",
    "    W = np.random.normal(size=(n_input, n_output))\n",
    "    # Create b at the right size, with zeros\n",
    "    b = np.zeros((n_output,))\n",
    "    nb_params = n_input * n_output + n_output\n",
    "    return W, b, nb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7850"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_training = train_images.shape[0] \n",
    "n_feature = train_images.shape[1] * train_images.shape[2]\n",
    "n_labels = 10\n",
    "W, b, nb_params = initLayer(n_feature, n_labels)\n",
    "nb_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(W, b, X):\n",
    "    \"\"\"\n",
    "    Perform the forward propagation\n",
    "    Inputs: W: the weights - numpy ndarray\n",
    "          : b: the bias - numpy ndarray\n",
    "          : X: the batch - numpy ndarray\n",
    "    Outputs: z: outputs - numpy ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    z = ...\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the output \n",
    "\n",
    "To obtain classification probabilities, we use the softmax function:\n",
    "$$ \\mathbf{o} = softmax(\\mathbf{z}) \\text{         with          } o_i = \\frac{\\exp(z_i)}{\\sum_{j=0}^{9} \\exp(z_j)} $$\n",
    "\n",
    "The usual difficulty with the softmax function is the possibility of overflow when the scores $z_i$ are already large. Since a softmax is not affected by a shift affecting the whole vector $\\mathbf{z}$:\n",
    "$$ \\frac{\\exp(z_i - c)}{\\sum_{j=0}^{9} \\exp(z_j - c)} =  \\frac{\\exp(c) \\exp(z_i)}{\\exp(c) \\sum_{j=0}^{9} \\exp(z_j)} = \\frac{\\exp(z_i)}{\\sum_{j=0}^{9} \\exp(z_j)}$$\n",
    "what trick can we use to ensure we will not encounter any overflow ? \n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Perform the softmax transformation to the pre-activation values\n",
    "    Inputs: z: the pre-activation values - numpy ndarray\n",
    "    Outputs: out: the activation values - numpy ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    out = ...\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making updates\n",
    "\n",
    "We define a learning rate $\\eta$. The goal is to be able to apply updates:\n",
    "$$ \\mathbf{W}^{t+1} = \\mathbf{W}^{t} + \\nabla_{\\mathbf{W}} l_{MLE} $$\n",
    "\n",
    "In order to do this, we will compute this gradient (and the bias) in the function ```update```. In the next function ```updateParams```, we will actually apply the update with regularization. \n",
    "\n",
    "Reminder: the gradient $\\nabla_{\\mathbf{W}} l_{MLE}$ is the matrix containing the partial derivatives \n",
    "$$ \\left[\\frac{\\delta l_{MLE}}{\\delta W_{ij}}\\right]_{i=1..784, j=1..10} $$\n",
    "**Remark**: Careful, the usual way of implementing this in python has the dimensions of $\\mathbf{W}$ reversed compared to the notation of the slides.\n",
    "\n",
    "Coordinate by coordinate, we obtain the following update: \n",
    "$$ W_{ij}^{t+1} = W_{ij}^{t} + \\eta \\frac{\\delta l_{MLE}}{\\delta W_{ij}} $$\n",
    "\n",
    "Via the chain rule, we obtain, for an input feature $i \\in [0, 783]$ and a output class $j \\in [0, 9]$: $$\\frac{\\delta l_{MLE}}{\\delta W_{ij}} = \\frac{\\delta l_{MLE}}{\\delta z_{j}} \\frac{\\delta z_j}{\\delta W_{ij}}$$ \n",
    "\n",
    "It's easy to compute that $\\frac{\\delta z_j}{\\delta W_{ij}} = x_i$\n",
    "\n",
    "We compute the softmax derivative, to obtain:\n",
    "$$ \\nabla_{\\mathbf{z}} l_{MLE} = \\mathbf{o} - \\mathbf{y} $$\n",
    "\n",
    "Hence, $\\frac{\\delta l_{MLE}}{\\delta z_{j}} = o_j - y_j$ and we obtain that $$\\frac{\\delta l_{MLE}}{\\delta W_{ij}} = (o_j - y_j) x_i$$\n",
    "\n",
    "This can easily be written as a scalar product, and a similar computation (even easier, actually) can be done for $\\mathbf{b}$. Noting $\\nabla_{\\mathbf{z}} l_{MLE} = \\mathbf{o} - \\mathbf{y}$ as ```grad``` in the following function, compute the gradients $\\nabla_{\\mathbf{W}} l_{MLE}$ and $\\nabla_{\\mathbf{b}} l_{MLE}$ in order to call the function ```updateParams```.\n",
    "\n",
    "Note: the regularizer and the weight_decay $\\lambda$ are used in ```updateParams```.\n",
    "\n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(eta, W, b, grad, X, regularizer, weight_decay):\n",
    "    \"\"\"\n",
    "    Perform the update of the parameters\n",
    "    Inputs: eta: the step-size of the gradient descent - float \n",
    "          : W: the weights - ndarray\n",
    "          : b: the bias -  ndarray\n",
    "          : grad: the gradient of the activations w.r.t. to the loss -  list of ndarray\n",
    "          : X: the data -  ndarray\n",
    "          : regularizer: 'L2' or None - the regularizer to be used in updateParams\n",
    "          : weight_decay: the weight decay to be used in updateParams - float\n",
    "    Outputs: W: the weights updated -  ndarray\n",
    "           : b: the bias updated -  ndarray\n",
    "    \"\"\"\n",
    "    grad_w = ...\n",
    "    grad_b = ...\n",
    "        \n",
    "    W = updateParams(W, grad_w, eta, regularizer, weight_decay)\n",
    "    b = updateParams(b, grad_b, eta, regularizer, weight_decay)\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update rule is affected by regularization. We implement two cases: No regularization, or L2 regularization. Use the two possible update rules to implement the following function: <div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(param, grad_param, eta, regularizer=None, weight_decay=0.):\n",
    "    \"\"\"\n",
    "    Perform the update of the parameters\n",
    "    Inputs: param: the network parameters - ndarray\n",
    "          : grad_param: the updates of the parameters - ndarray\n",
    "          : eta: the step-size of the gradient descent - float\n",
    "          : weight_decay: the weight-decay - float\n",
    "    Outputs: the parameters updated - ndarray\n",
    "    \"\"\"\n",
    "    if regularizer==None:\n",
    "        grad = ...\n",
    "        return grad\n",
    "    elif regularizer=='L2':\n",
    "        grad = ...\n",
    "        return grad\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Accuracy\n",
    "\n",
    "Here, we simply use the model to predict the class (by taking the argmax of the output !) for every example in ```X```, and count the number of times the model is right, to output the accuracy.\n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAcc(W, b, X, labels):\n",
    "    \"\"\"\n",
    "    Compute the loss value of the current network on the full batch\n",
    "    Inputs: act_func: the activation function - function\n",
    "          : W: the weights - list of ndarray\n",
    "          : B: the bias - list of ndarray\n",
    "          : X: the batch - ndarray\n",
    "          : labels: the labels corresponding to the batch\n",
    "    Outputs: loss: the negative log-likelihood - float\n",
    "           : accuracy: the ratio of examples that are well-classified - float\n",
    "    \"\"\" \n",
    "    # Forward propagation\n",
    "    z = ...\n",
    " \n",
    "    # Compute the softmax and the prediction\n",
    "    out = ...\n",
    "    pred = ...\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    accuracy = ...\n",
    "      \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training\n",
    "\n",
    "The following hyperparameters are given. Next, we can assemble all the function previously defined to implement a training loop. We will train the classifier on **one epoch**, meaning that the model will see each training example once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "eta = 0.01\n",
    "regularizer = 'L2'\n",
    "weight_decay = 0.0001\n",
    "\n",
    "# Training\n",
    "log_interval = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structures for plotting\n",
    "g_train_acc=[]\n",
    "g_valid_acc=[]\n",
    "\n",
    "#######################\n",
    "### Learning process ##\n",
    "#######################\n",
    "for j in range(n_training):\n",
    "    # Getting the example\n",
    "    X, y = ...\n",
    "\n",
    "    # Forward propagation\n",
    "    z = ...\n",
    "\n",
    "    # Compute the softmax\n",
    "    out = ...\n",
    "        \n",
    "    # Compute the gradient at the top layer\n",
    "    derror = out - y # This is o - y \n",
    "\n",
    "    # Update the parameters\n",
    "    W, b = ...\n",
    "\n",
    "    if j % log_interval == 0:\n",
    "        # Every log_interval examples, look at the training accuracy\n",
    "        train_accuracy = computeAcc(W, b, train_images, train_labels) \n",
    "\n",
    "        # And the testing accuracy\n",
    "        test_accuracy = computeAcc(W, b, test_images, test_labels) \n",
    "\n",
    "        g_train_acc.append(train_accuracy)\n",
    "        g_valid_acc.append(test_accuracy)\n",
    "        result_line = str(int(j)) + \" \" + str(train_accuracy) + \" \" + str(test_accuracy) + \" \" + str(eta)\n",
    "        print(result_line)\n",
    "\n",
    "g_train_acc.append(train_accuracy)\n",
    "g_valid_acc.append(valid_accuracy)\n",
    "result_line = \"Final result:\" + \" \" + str(train_accuracy) + \" \" + str(valid_accuracy) + \" \" + str(eta)\n",
    "print(result_line)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you say about the performance of this simple linear classifier ?\n",
    "<div class='alert alert-block alert-warning'>\n",
    "            Answer:</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second part: Autoencoder with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder and PCA\n",
    "\n",
    "First, we will try to connect the representation produced by Principal Component Analysis with what is learnt by a simple, linear, autoencoder. We will use the ```scikit-learn``` implementation of the ```PCA``` to obtain the two first components (hint: use the attribute ```.components_```), and visualize them:\n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Let's find the first 2 PCA components\n",
    "num_components = 2\n",
    "pca = PCA(...).fit(...)\n",
    "\n",
    "# Reshape so they resemble images and we can print them\n",
    "eigen_mnist = pca.components_.reshape(...)\n",
    "\n",
    "# Show the reshaped principal components\n",
    "f, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(eigen_mnist[0], cmap='gray')\n",
    "ax[0].set_xlabel('First Principal Component')\n",
    "ax[1].imshow(eigen_mnist[1], cmap='gray')\n",
    "ax[1].set_xlabel('Second Principal Component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the variance explained by those components\n",
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the visualization in relation to the variance explained by only keeping the two principal components:\n",
    "<div class='alert alert-block alert-warning'>\n",
    "            Answer:</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Autoencoder with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use Keras to implement the autoencoder. You can take a look at this [cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras_Cheat_Sheet_Python.pdf) for some basic commands to use keras.\n",
    "\n",
    "In this first case, we implement a **simple linear autoencoder**. Build it in order to have the same capacity as the PCA decomposition (2 hidden dimensions !) we made just above. \n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_layer = ...\n",
    "\n",
    "# Encoding layer\n",
    "latent_view = ...\n",
    "\n",
    "# Decoding layer\n",
    "output_layer = ...\n",
    "\n",
    "ae_model = Model(input_layer, output_layer, name='ae_model')\n",
    "ae_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What loss shoud we use ? Choose the usual one and import it directly from Keras. You can use a simple ```SGD``` optimizer, and then compile the model; finally, train it to rebuild images from the original examples. \n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import ...\n",
    "loss = ...\n",
    "\n",
    "optimizer = SGD(lr=1e-1) \n",
    "ae_model.compile(optimizer=optimizer, loss=loss) \n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "# No noise here - we want to train a simple auto-encoder and compare visually with PCA\n",
    "history = ae_model.fit(...,\n",
    "                       ...,\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       verbose=1,\n",
    "                       shuffle=True,\n",
    "                       validation_data=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that the name of your layer (obtained through the command ```model.summary()```) is ```'layer'```, here is the way to obtained the weights. Visualize the weights of the encoder and compare them to the two components obtained through the PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = ae_model.get_layer('layer').get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the two dimensions of the encoder, in a similar manner to the principal components\n",
    "# (after reshaping them as images !)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, visualize the images rebuilt by the network !\n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few images at random: look from n\n",
    "n = np.random.randint(0,len(test_images)-5)\n",
    "\n",
    "# Plot a few images from n  \n",
    "f, ax = plt.subplots(1,5)\n",
    "for i,a in enumerate(range(n,n+5)):\n",
    "    ...\n",
    "    \n",
    "# Get the prediction from the model \n",
    "\n",
    "\n",
    "# ... and plot them \n",
    "f, ax = plt.subplots(1,5)\n",
    "for i,a in enumerate(range(n,n+5)):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same ( = build a new model) with a latent dimension that is largely higher than 2. Compare the visualizations and the images that are rebuilt. \n",
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: De-noising Autoencoder\n",
    "\n",
    "Now, we can implement a **de-noising autoencoder**. The following function will transform an array of images by adding it random noise. Create a new autoencoder model, this time with **more layers** and **non-linear activations** (like the ReLU) and train it to rebuild the de-noised images. Display some testing images, with noise, and re-built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(array):\n",
    "    \"\"\"\n",
    "    Adds random noise to each image in the supplied array.\n",
    "    \"\"\"\n",
    "    noise_factor = 0.4\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "    return noisy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data with added noise\n",
    "noisy_train_images = noise(train_images)\n",
    "noisy_test_images = noise(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "            Code:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the images with noise against the originals\n",
    "\n",
    "\n",
    "# Build a new model with more layers and Relu activations\n",
    "\n",
    "\n",
    "# Compile it but here, use noised data as inputs !\n",
    "\n",
    "\n",
    "# Visualize the images rebuilt by the model !\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that we normalize the images to be in the 0-1 range, what other loss function could we use ?\n",
    "<div class='alert alert-block alert-warning'>\n",
    "            Answer:</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP4_1_empty.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
